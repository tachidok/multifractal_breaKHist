{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tachidok/multifractal_breaKHist/blob/main/Multifractal_based_on_slide_ids.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sticky-compromise",
      "metadata": {
        "id": "sticky-compromise"
      },
      "source": [
        "# Cancer cells classification based on multifractal dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lHB0YsS_a0f4",
      "metadata": {
        "id": "lHB0YsS_a0f4"
      },
      "source": [
        "# Install non default packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q0N6LX9Sa7Pq",
      "metadata": {
        "id": "Q0N6LX9Sa7Pq"
      },
      "outputs": [],
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn\n",
        "#!pip install -U lazypredict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run this if running using local environment"
      ],
      "metadata": {
        "id": "5N3IxVF9ubxd"
      },
      "id": "5N3IxVF9ubxd"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U imblearn"
      ],
      "metadata": {
        "id": "OAKiRhLouSYy"
      },
      "id": "OAKiRhLouSYy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "concrete-airport",
      "metadata": {
        "id": "concrete-airport"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hollywood-monitoring",
      "metadata": {
        "id": "hollywood-monitoring"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Basic plotting\n",
        "import numpy as np\n",
        "#import cv2\n",
        "import pylab as pl\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Basic data base management and statistical tools\n",
        "import pandas as pd\n",
        "#import seaborn as sns\n",
        "\n",
        "# Classification tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Classification models\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# Metrics and tools\n",
        "from sklearn import preprocessing\n",
        "# Metrics (accuracy, precision, recall, F_beta, AUC)\n",
        "from sklearn import metrics\n",
        "# Get the time for each classifier\n",
        "from time import time\n",
        "\n",
        "# Manage unbalance data\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "# Visualization\n",
        "from sklearn import tree\n",
        "\n",
        "# AutoML\n",
        "#import autosklearn.classification\n",
        "#from lazypredict.Supervised import LazyClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ThcXctvkgiSa",
      "metadata": {
        "id": "ThcXctvkgiSa"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c48b4e",
      "metadata": {
        "id": "53c48b4e"
      },
      "source": [
        "## Load from local device (not used in colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd3e665",
      "metadata": {
        "id": "0cd3e665"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('../data/csvfile_all.csv')\n",
        "#df = pd.read_csv('../data/csv_files/02_csv_06052021/csvfile_all.csv')\n",
        "#df = pd.read_csv('../data/csv_files/03_csv_files_bc_p23/csvfile_all.csv')\n",
        "#df = pd.read_csv('../data/csv_files/04_csv_files_bc_p456/csvfile_all.csv')\n",
        "#df = pd.read_csv('../data/csv_files/05_csv_files_seg_bc234/csvfile_all.csv')\n",
        "#df = pd.read_csv('../data/csv_files/06_csv_files_heq_seg_bc234_log/csvfile_all.csv')\n",
        "#df = pd.read_csv('../data/csv_files/07_csv_files_heq_segthadapt_bc234_log/csvfile_all.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xrmnN3atrk3B",
      "metadata": {
        "id": "xrmnN3atrk3B"
      },
      "source": [
        "## Load to Google Drive from local file system using Python code (not used in colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1NSKYkXfrzC2",
      "metadata": {
        "id": "1NSKYkXfrzC2"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d13ae963",
      "metadata": {
        "id": "d13ae963"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-sW7aToesHTs",
      "metadata": {
        "id": "-sW7aToesHTs"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('csvfile_all.csv')\n",
        "df = pd.read_csv('./dataset/csv_files/06_csv_files_heq_seg_bc_234_log/csvfile_all.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcfca5f",
      "metadata": {
        "id": "efcfca5f"
      },
      "source": [
        "## Load from Google Drive (used in colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c52917",
      "metadata": {
        "id": "e2c52917"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PJF_G_KlgoTL",
      "metadata": {
        "id": "PJF_G_KlgoTL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "centered-wright",
      "metadata": {
        "id": "centered-wright"
      },
      "source": [
        "### Where are we? (current path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unlikely-netscape",
      "metadata": {
        "id": "unlikely-netscape"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "robust-rabbit",
      "metadata": {
        "id": "robust-rabbit"
      },
      "source": [
        "### Load data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "governing-reference",
      "metadata": {
        "id": "governing-reference"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/dataset/cancer/csv_files/06_csv_files_heq_seg__bc_234_log/csvfile_all.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kuYAdMJgnP2g",
      "metadata": {
        "id": "kuYAdMJgnP2g"
      },
      "source": [
        "# Output dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comfortable-equilibrium",
      "metadata": {
        "id": "comfortable-equilibrium"
      },
      "outputs": [],
      "source": [
        "# Output the data frame\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "southwest-madagascar",
      "metadata": {
        "id": "southwest-madagascar"
      },
      "source": [
        "# Pre-process data frames\n",
        "1. Get the number of registers prior to pre-processing\n",
        "2. Drop 'NaN' entries\n",
        "3. Drop duplicates\n",
        "4. Get the final number of registers post pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eligible-welsh",
      "metadata": {
        "id": "eligible-welsh"
      },
      "outputs": [],
      "source": [
        "# Get the number of registers\n",
        "n_registers_prior_preprocessing = df.shape\n",
        "# Drop 'NaN' entries\n",
        "df = df.dropna()\n",
        "# Drop duplicates\n",
        "df = df.drop_duplicates()\n",
        "# Drop the column called unnamed, do the operation \"inplace\", that means in the same DataFrame, and remove the \"axis=1\", that means the column, not the row\n",
        "#df.drop(\"0\", inplace = True, axis = 1)#disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=estimator.classes_)\n",
        "#disp.plot()\n",
        "#plt.title(\"Confusion matrix\")\n",
        "#plt.figure(figsize=(10,10))\n",
        "#plt.show()\n",
        "#df = df.reset_index()\n",
        "n_registers_post_preprocessing = df.shape\n",
        "print(f\"Number of registers prior pre-processing {n_registers_prior_preprocessing}\")\n",
        "print(f\"Number of registers post pre-processing {n_registers_post_preprocessing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fGb_6tws7RTD",
      "metadata": {
        "id": "fGb_6tws7RTD"
      },
      "source": [
        "# Get information about the dataset\n",
        "* Number of samples for each tumor class or tumor type\n",
        "\n",
        "* Tumor type\n",
        "\n",
        "  * A = Adenosis\n",
        "  * F = Fibroadenoma\n",
        "  * TA = Tubular Adenoma\n",
        "  * PT = Phyllodes Tumor\n",
        "\n",
        "  * DC = Ductal Carcicoma\n",
        "  * LC = Lobular Carcicoma\n",
        "  * MC = Mucinous Carcicoma (Colloid)\n",
        "  * PC = Papillary Carcicoma\n",
        "\n",
        "* Tumor class\n",
        "\n",
        "  * B = Benign\n",
        "  * M = Malign\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLM_zlf-_k8u",
      "metadata": {
        "id": "qLM_zlf-_k8u"
      },
      "outputs": [],
      "source": [
        "# Count the number of instances of each tumor type\n",
        "print(\"Full dataset: Number of instances for each tumor type\")\n",
        "print(df['tumor_type'].value_counts())\n",
        "\n",
        "# Count the number of instances of each tumor class\n",
        "print(\"\\nFull dataset: Number of instances for each tumor class\")\n",
        "print(df['tumor_class'].value_counts())\n",
        "\n",
        "# Create groups based on magnification\n",
        "groups_by_magnification = df.groupby('magnification')\n",
        "\n",
        "# Get the groups by magnification\n",
        "group_40x = groups_by_magnification.get_group(40)\n",
        "group_100x = groups_by_magnification.get_group(100)\n",
        "group_200x = groups_by_magnification.get_group(200)\n",
        "group_400x = groups_by_magnification.get_group(400)\n",
        "\n",
        "# Describe the sub-dataset\n",
        "print(\"\\n\\n40x dataset: describe()\")\n",
        "print(group_40x['tumor_type'].describe())\n",
        "# Get the number of instances of each tumor type for this magnification\n",
        "print(\"\\n40x dataset: Number of instances for each tumor type\")\n",
        "print(group_40x['tumor_type'].value_counts())\n",
        "# Get the number of instances of each tumor class for this magnification\n",
        "print(\"\\n40x dataset: Number of instances for each tumor class\")\n",
        "print(group_40x['tumor_class'].value_counts())\n",
        "\n",
        "# Describe the sub-dataset\n",
        "print(\"\\n\\n100x dataset: describe()\")\n",
        "print(group_100x['tumor_type'].describe())\n",
        "# Get the number of instances of each tumor type for this magnification\n",
        "print(\"\\n100x dataset: Number of instances for each tumor type\")\n",
        "print(group_100x['tumor_type'].value_counts())\n",
        "# Get the number of instances of each tumor class for this magnification\n",
        "print(\"\\n100x dataset: Number of instances for each tumor class\")\n",
        "print(group_100x['tumor_class'].value_counts())\n",
        "\n",
        "# Describe the sub-dataset\n",
        "print(\"\\n\\n200x dataset: describe()\")\n",
        "print(group_200x['tumor_type'].describe())\n",
        "# Get the number of instances of each tumor type for this magnification\n",
        "print(\"\\n200x dataset: Number of instances for each tumor type\")\n",
        "print(group_200x['tumor_type'].value_counts())\n",
        "# Get the number of instances of each tumor class for this magnification\n",
        "print(\"\\n200x dataset: Number of instances for each tumor class\")\n",
        "print(group_200x['tumor_class'].value_counts())\n",
        "\n",
        "# Describe the sub-dataset\n",
        "print(\"\\n\\n400x dataset: describe()\")\n",
        "print(group_400x['tumor_type'].describe())\n",
        "# Get the number of instances of each tumor type for this magnification\n",
        "print(\"\\n400x dataset: Number of instances for each tumor type\")\n",
        "print(group_400x['tumor_type'].value_counts())\n",
        "# Get the number of instances of each tumor class for this magnification\n",
        "print(\"\\n400x dataset: Number of instances for each tumor class\")\n",
        "print(group_400x['tumor_class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "original-diameter",
      "metadata": {
        "id": "original-diameter"
      },
      "source": [
        "# Plot data as it is!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ed567c",
      "metadata": {
        "id": "14ed567c"
      },
      "source": [
        "## Print the name of the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "appreciated-welding",
      "metadata": {
        "id": "appreciated-welding"
      },
      "outputs": [],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39759490",
      "metadata": {
        "id": "39759490"
      },
      "source": [
        "## Plot Image vs fd_canny_100_200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "remarkable-affect",
      "metadata": {
        "id": "remarkable-affect",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ax1 = df.plot.scatter(x='index', y='fd_canny_100_200')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15e52d5",
      "metadata": {
        "id": "b15e52d5"
      },
      "source": [
        "## Plot Image vs fd_canny_150_250_as5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a61bd338",
      "metadata": {
        "id": "a61bd338"
      },
      "outputs": [],
      "source": [
        "ax2 = df.plot.scatter(x='index', y='fd_canny_150_250_as5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff7b193",
      "metadata": {
        "id": "aff7b193"
      },
      "source": [
        "## Plot fd_canny_100_200 vs fd_canny_150_250_as5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae78b83",
      "metadata": {
        "id": "2ae78b83"
      },
      "outputs": [],
      "source": [
        "ax3 = df.plot.scatter(x='fd_canny_100_200', y='fd_canny_150_250_as5')\n",
        "#df.plot.scatter(x='index',y='magnification')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "copyrighted-transaction",
      "metadata": {
        "id": "copyrighted-transaction"
      },
      "source": [
        "# Strategy to create the new data frame\n",
        "\n",
        "1.   Extract the slide ID/patient ID and add it into the data frame\n",
        "2.   Split observations based on patients IDs/slides IDs\n",
        "3.   Split the patients sub-groups per magninfication\n",
        "4.   Create as many combinations as possible (memory constraints) by taking one element of each magnification sub-group\n",
        "5.   For each combination assign a tumor type and tumor class based on the patient IDs/slides IDs labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e9e28c7",
      "metadata": {
        "id": "0e9e28c7"
      },
      "source": [
        "## Extract the slide ID/patient ID from the image name and add it as a new column to the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dwZMxPqcPVIk",
      "metadata": {
        "id": "dwZMxPqcPVIk"
      },
      "outputs": [],
      "source": [
        "# Get the image name column into a numpy array\n",
        "names_array = df['image_name'].to_numpy()\n",
        "# Get the number of elements in the column\n",
        "n_names = len(names_array)\n",
        "# Create an empty list\n",
        "list_slide_ids = []#np.empty(n_names)\n",
        "#list_figure_number = []#np.empty(n_names)\n",
        "\n",
        "# Loop over all images\n",
        "for i in range(n_names):\n",
        "\n",
        "  # Get the full name of the image\n",
        "  image_name = names_array[i]\n",
        "\n",
        "  # Split the name by '-'\n",
        "  image_features = image_name.split(\"-\")\n",
        "\n",
        "  # Append the element at position 2 (which is the slide id)\n",
        "  list_slide_ids.append(image_features[2])\n",
        "\n",
        "  # Get the element at position 4 which is the figure number with the image extension [png], then get only the number and forget about the extension\n",
        "  #list_figure_number.append(image_features[4].split(\".\")[0])\n",
        "\n",
        "  #print(\"Names: %s %s\" % (list_slide_ids[i], list_figure_number[i]))\n",
        "\n",
        "# Add the column to the data frame\n",
        "df['slide_id'] = list_slide_ids\n",
        "#df['figure_number'] = list_figure_number\n",
        "\n",
        "# Show the data frame\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_rH2Z4jElLLI",
      "metadata": {
        "id": "_rH2Z4jElLLI"
      },
      "source": [
        "## Drop columns and create a new data frame from groups\n",
        "\n",
        "1. Drop 'path' and 'image_name' columns\n",
        "2. Create groups by slide ids, then create subgroups by magnification and combine data into a single observation\n",
        "\n",
        " * Each row or observation in the data frame has the following structure\n",
        "\n",
        "    * Canny feature for 40x - 01\n",
        "    * Canny feature for 40x - 02\n",
        "    * Canny feature for 100x - 01\n",
        "    * Canny feature for 100x - 02\n",
        "    * Canny feature for 200x - 01\n",
        "    * Canny feature for 200x - 02\n",
        "    * Canny feature for 400x - 01\n",
        "    * Canny feature for 400x - 02\n",
        "    * Tumor class\n",
        "    * Tumor type\n",
        "\n",
        "  The variable 'n_max_ele_per_group' constraint the number of images to take for each magnification group. This is used due to memory constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ck---9FWa5t",
      "metadata": {
        "id": "0ck---9FWa5t"
      },
      "outputs": [],
      "source": [
        "# Rewrite this section by using the itertools package that implements the cartesian product of multiple sets\n",
        "\n",
        "# https://www.geeksforgeeks.org/python-itertools-product/\n",
        "\n",
        "# Sort the data frame by slide ids\n",
        "#sorted_df = df.sort_values('slide_id', ascending=False)\n",
        "# Drop the path of the image and the full image name\n",
        "reduced_df = df.drop(columns=['path', 'image_name'])\n",
        "# Create groups by the slide ids\n",
        "group_df = reduced_df.groupby('slide_id')\n",
        "\n",
        "# The list to store the new data (get both canny features for each magnification)\n",
        "list_magnification_40x_canny_01 = []\n",
        "list_magnification_40x_canny_02 = []\n",
        "list_magnification_100x_canny_01 = []\n",
        "list_magnification_100x_canny_02 = []\n",
        "list_magnification_200x_canny_01 = []\n",
        "list_magnification_200x_canny_02 = []\n",
        "list_magnification_400x_canny_01 = []\n",
        "list_magnification_400x_canny_02 = []\n",
        "# Also include the tumor class and the tumor type\n",
        "list_tumor_class = []\n",
        "list_tumor_type = []\n",
        "\n",
        "counter = 0\n",
        "\n",
        "# List the groups\n",
        "for slide_id, group in group_df:\n",
        "\n",
        "  print(f\"Slide id: {slide_id}\")\n",
        "  print(\"Patient number: %d\" % counter)\n",
        "  counter += 1\n",
        "\n",
        "  # Create groups based on magnification\n",
        "  sub_groups_by_magnification = group.groupby('magnification')\n",
        "\n",
        "  # Get the groups by magnification\n",
        "  group_40x = sub_groups_by_magnification.get_group(40)\n",
        "  group_100x = sub_groups_by_magnification.get_group(100)\n",
        "  group_200x = sub_groups_by_magnification.get_group(200)\n",
        "  group_400x = sub_groups_by_magnification.get_group(400)\n",
        "\n",
        "  # Get a numpy representation of the columns with the canny features\n",
        "  canny_values_01_40x = group_40x['fd_canny_100_200'].to_numpy()\n",
        "  canny_values_02_40x = group_40x['fd_canny_150_250_as5'].to_numpy()\n",
        "  canny_values_01_100x = group_100x['fd_canny_100_200'].to_numpy()\n",
        "  canny_values_02_100x = group_100x['fd_canny_150_250_as5'].to_numpy()\n",
        "  canny_values_01_200x = group_200x['fd_canny_100_200'].to_numpy()\n",
        "  canny_values_02_200x = group_200x['fd_canny_150_250_as5'].to_numpy()\n",
        "  canny_values_01_400x = group_400x['fd_canny_100_200'].to_numpy()\n",
        "  canny_values_02_400x = group_400x['fd_canny_150_250_as5'].to_numpy()\n",
        "\n",
        "  # Get a numpy representation of the columns with the tumor class and tumor type, all the tumor class and tumor type are the same\n",
        "  tumor_class_np = group_40x['tumor_class'].to_numpy()\n",
        "  tumor_type_np = group_40x['tumor_type'].to_numpy()\n",
        "\n",
        "  # Get the number of images per group\n",
        "  n_images_40x = len(canny_values_01_40x)\n",
        "  n_images_100x = len(canny_values_01_100x)\n",
        "  n_images_200x = len(canny_values_01_200x)\n",
        "  n_images_400x = len(canny_values_01_400x)\n",
        "\n",
        "  # Print the number of images per each magnification\n",
        "  print(f\"Number of images per 40x {n_images_40x}\")\n",
        "  print(f\"Number of images per 100x {n_images_100x}\")\n",
        "  print(f\"Number of images per 200x {n_images_200x}\")\n",
        "  print(f\"Number of images per 400x {n_images_400x}\")\n",
        "\n",
        "  # Set a maximum number of images to consider per group (this is due to memory limitations)\n",
        "  n_max_img_per_group = 10\n",
        "\n",
        "  # Create a new data frame with the combinations of the canny values of the images\n",
        "  # [canny_40x, canny_40x, canny_100x, canny_100x, canny_200x, canny_200x, canny_400x, canny_400x, tumor_class, tumor_type]\n",
        "  for i in range(min(n_images_40x, n_max_img_per_group)):\n",
        "    for j in range(min(n_images_100x, n_max_img_per_group)):\n",
        "      for k in range(min(n_images_200x, n_max_img_per_group)):\n",
        "        for m in range(min(n_images_400x, n_max_img_per_group)):\n",
        "\n",
        "          feature_canny_01_40x = canny_values_01_40x[i]\n",
        "          feature_canny_02_40x = canny_values_02_40x[i]\n",
        "          feature_canny_01_100x = canny_values_01_100x[j]\n",
        "          feature_canny_02_100x = canny_values_02_100x[j]\n",
        "          feature_canny_01_200x = canny_values_01_200x[k]\n",
        "          feature_canny_02_200x = canny_values_02_200x[k]\n",
        "          feature_canny_01_400x = canny_values_01_400x[m]\n",
        "          feature_canny_02_400x = canny_values_02_400x[m]\n",
        "\n",
        "          #print(f\"Slide id {name}, m40x {feature_canny_01_40x} {feature_canny_02_40x}, m100x {feature_canny_01_100x} {feature_canny_02_100x}, m200x {feature_canny_01_200x} {feature_canny_02_200x}, m400x {feature_canny_01_400x} {feature_canny_02_400x}\")\n",
        "          list_magnification_40x_canny_01.append(feature_canny_01_40x)\n",
        "          list_magnification_40x_canny_02.append(feature_canny_02_40x)\n",
        "          list_magnification_100x_canny_01.append(feature_canny_01_100x)\n",
        "          list_magnification_100x_canny_02.append(feature_canny_02_100x)\n",
        "          list_magnification_200x_canny_01.append(feature_canny_01_200x)\n",
        "          list_magnification_200x_canny_02.append(feature_canny_02_200x)\n",
        "          list_magnification_400x_canny_01.append(feature_canny_01_400x)\n",
        "          list_magnification_400x_canny_02.append(feature_canny_02_400x)\n",
        "\n",
        "          # We take the tumor type and class from the 40x image data set, it should be the same for all magnifications\n",
        "          list_tumor_class.append(tumor_class_np[i])\n",
        "          list_tumor_type.append(tumor_type_np[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M1IE8e7Nn9bx",
      "metadata": {
        "id": "M1IE8e7Nn9bx"
      },
      "source": [
        "## Create the new data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y_rDUlRnn6RL",
      "metadata": {
        "id": "Y_rDUlRnn6RL"
      },
      "outputs": [],
      "source": [
        "# Create the data frame with the new combined data\n",
        "#new_df = pd.DataFrame([list_magnification_40x_canny_01, list_magnification_40x_canny_02, list_magnification_100x_canny_01, list_magnification_100x_canny_02, list_magnification_200x_canny_01, list_magnification_200x_canny_02, list_magnification_400x_canny_01, list_magnification_400x_canny_02, list_tumor_class, list_tumor_type], columns = ['canny_values_01_40x', 'canny_values_02_40x', 'canny_values_01_100x', 'canny_values_02_100x', 'canny_values_01_200x', 'canny_values_02_200x', 'canny_values_01_400x', 'canny_values_02_400x', 'tumor_class', 'tumor_type'])\n",
        "new_df = pd.DataFrame()\n",
        "\n",
        "new_df['canny_values_01_40x'] = list_magnification_40x_canny_01\n",
        "new_df['canny_values_02_40x'] = list_magnification_40x_canny_02\n",
        "new_df['canny_values_01_100x'] = list_magnification_100x_canny_01\n",
        "new_df['canny_values_02_100x'] = list_magnification_100x_canny_02\n",
        "new_df['canny_values_01_200x'] = list_magnification_200x_canny_01\n",
        "new_df['canny_values_02_200x'] = list_magnification_200x_canny_02\n",
        "new_df['canny_values_01_400x'] = list_magnification_400x_canny_01\n",
        "new_df['canny_values_02_400x'] = list_magnification_400x_canny_02\n",
        "new_df['tumor_class'] = list_tumor_class\n",
        "new_df['tumor_type'] = list_tumor_type\n",
        "\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hWA3E05YFz2l",
      "metadata": {
        "id": "hWA3E05YFz2l"
      },
      "source": [
        "# Get information about the new dataset\n",
        "* Number of instances per tumor class and tumor type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dUtEdyNmFzmX",
      "metadata": {
        "id": "dUtEdyNmFzmX"
      },
      "outputs": [],
      "source": [
        "# Describe the dataset\n",
        "print(\"\\n\\nNew dataset: describe()\")\n",
        "print(new_df['tumor_type'].describe())\n",
        "# Get the number of instances of each tumor type\n",
        "print(\"\\nNew dataset: Number of instances for each tumor type\")\n",
        "print(new_df['tumor_type'].value_counts())\n",
        "# Get the number of instances of each tumor class\n",
        "print(\"\\nNew dataset: Number of instances for each tumor class\")\n",
        "print(new_df['tumor_class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389b489c",
      "metadata": {
        "id": "389b489c"
      },
      "source": [
        "# Save the new data frame to disk (not run due to large file size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VJBlH61cry5C",
      "metadata": {
        "id": "VJBlH61cry5C"
      },
      "outputs": [],
      "source": [
        "# Save the data frame\n",
        "#new_df.to_csv(rf'csvfile_new_df_grp_max_20.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jB87anN_WRDz",
      "metadata": {
        "id": "jB87anN_WRDz"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0d634f",
      "metadata": {
        "id": "9b0d634f"
      },
      "source": [
        "## Data selection\n",
        "* (Option 1) Tumor type\n",
        "\n",
        "  * A = Adenosis\n",
        "  * F = Fibroadenoma\n",
        "  * TA = Tubular Adenoma\n",
        "  * PT = Phyllodes Tumor\n",
        "\n",
        "  * DC = Ductal Carcicoma\n",
        "  * LC = Lobular Carcicoma\n",
        "  * MC = Mucinous Carcicoma (Colloid)\n",
        "  * PC = Papillary Carcicoma\n",
        "\n",
        "* (Option 2) Tumor class\n",
        "\n",
        "  * B = Benign\n",
        "  * M = Malign"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nc8SJh0hQqgn",
      "metadata": {
        "id": "Nc8SJh0hQqgn"
      },
      "source": [
        "### Option 1: Remove the tumor class column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87_giggHSCSK",
      "metadata": {
        "id": "87_giggHSCSK"
      },
      "outputs": [],
      "source": [
        "# Drop the tumor class column\n",
        "#new_df = new_df.drop(columns=['tumor_class'])\n",
        "#new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Knq90kyyT1Hs",
      "metadata": {
        "id": "Knq90kyyT1Hs"
      },
      "source": [
        "### Option 2: Remove the tumor type column\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zj7y5wzZTyCc",
      "metadata": {
        "id": "zj7y5wzZTyCc"
      },
      "outputs": [],
      "source": [
        "# Drop the tumor class column\n",
        "new_df = new_df.drop(columns=['tumor_type'])\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0C6PsO51GuUs",
      "metadata": {
        "id": "0C6PsO51GuUs"
      },
      "source": [
        "## Get information again\n",
        "* Number of tumor type/class in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ExuUhrVDOrRn",
      "metadata": {
        "id": "ExuUhrVDOrRn"
      },
      "outputs": [],
      "source": [
        "# Describe the dataset\n",
        "#print(\"\\n\\nNew dataset: describe()\")\n",
        "#print(new_df['tumor_type'].describe())\n",
        "# Get the number of instances of each tumor type\n",
        "#print(\"\\nNew dataset: Number of instances for each tumor type\")\n",
        "#print(new_df['tumor_type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_jYzO50JG1M3",
      "metadata": {
        "id": "_jYzO50JG1M3"
      },
      "outputs": [],
      "source": [
        "# Describe the dataset\n",
        "print(\"\\n\\nNew dataset: describe()\")\n",
        "#print(new_df['tumor_class'].describe())\n",
        "# Get the number of instances of each tumor class\n",
        "print(\"\\nNew dataset: Number of instances for each tumor class\")\n",
        "print(new_df['tumor_class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aWAI13BWUdsi",
      "metadata": {
        "id": "aWAI13BWUdsi"
      },
      "source": [
        "## Split data intro training and testing groups\n",
        "\n",
        "* X stores all observations\n",
        "* y stores all predictions\n",
        "\n",
        "* X_train stores training group observations\n",
        "* y_train stores training group predictions\n",
        "\n",
        "* X_test stores testing group observations\n",
        "* y_test stores testing group predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DXauk6jfUgc6",
      "metadata": {
        "id": "DXauk6jfUgc6"
      },
      "outputs": [],
      "source": [
        "# Get the observations/input values from the new data frame\n",
        "#X = np.c_[new_df[['canny_values_01_40x', 'canny_values_02_40x', 'canny_values_01_100x', 'canny_values_02_100x', 'canny_values_01_200x', 'canny_values_02_200x', 'canny_values_01_400x', 'canny_values_02_400x']]]\n",
        "# Get the predictions (from tge \"tumor class\" or the \"tumor type\" column)\n",
        "#y = np.c_[new_df['tumor_class']]\n",
        "#y = np.c_[new_df['tumor_type']]\n",
        "\n",
        "X = new_df[['canny_values_01_40x', 'canny_values_02_40x', 'canny_values_01_100x', 'canny_values_02_100x', 'canny_values_01_200x', 'canny_values_02_200x', 'canny_values_01_400x', 'canny_values_02_400x']]\n",
        "# Get the predictions (from tge \"tumor class\" or the \"tumor type\" column)\n",
        "y = new_df['tumor_class']\n",
        "#y = new_df['tumor_type']\n",
        "\n",
        "# Split the data\n",
        "percentage_for_test_size = 0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = percentage_for_test_size, shuffle = True)\n",
        "print(\"Full dataset size\")\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(\"\\nTraining dataset size\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"\\nTesting dataset size\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gNVpmFhSXsR8",
      "metadata": {
        "id": "gNVpmFhSXsR8"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c06897",
      "metadata": {
        "id": "82c06897"
      },
      "source": [
        "### Scaling (training and testing data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dP83SXQSX2wx",
      "metadata": {
        "id": "dP83SXQSX2wx"
      },
      "outputs": [],
      "source": [
        "#scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47cb44cc",
      "metadata": {
        "id": "47cb44cc"
      },
      "source": [
        "### Correct the training vector shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b940bb36",
      "metadata": {
        "id": "b940bb36"
      },
      "outputs": [],
      "source": [
        "# Correct the issue of size (numpy format)\n",
        "y_train = np.ravel(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p3WXYgwvZVcG",
      "metadata": {
        "id": "p3WXYgwvZVcG"
      },
      "source": [
        "### Manage unbalanced data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m2mIobv3Zd3E",
      "metadata": {
        "id": "m2mIobv3Zd3E"
      },
      "outputs": [],
      "source": [
        "# Print data prior unbalance management\n",
        "print(\"Before unbalance management\", Counter(y_train))\n",
        "\n",
        "# Instantiate sampler strategy\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "\n",
        "# Apply strategy\n",
        "X_train_balanced, y_train_balanced = undersample.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Print data after unbalance management\n",
        "print(\"After unbalance management\", Counter(y_train_balanced))\n",
        "\n",
        "print(\"\\nTraining dataset size\")\n",
        "print(X_train_balanced.shape)\n",
        "print(y_train_balanced.shape)\n",
        "print(\"\\nTesting dataset size\")\n",
        "print(X_test_scaled.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cK4PymsNJ38S",
      "metadata": {
        "id": "cK4PymsNJ38S"
      },
      "source": [
        "## Compute feature importance\n",
        "* Use a decision tree to get the importance of each feature on classification\n",
        "* Use all dataset since we want to know the feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k-7T3TKGKBjp",
      "metadata": {
        "id": "k-7T3TKGKBjp"
      },
      "outputs": [],
      "source": [
        "# Instance the decision tree\n",
        "tree = DecisionTreeClassifier(max_depth = 10, random_state=0)\n",
        "# Fit with the whole dataset to get feature importance\n",
        "tree.fit(X, y)\n",
        "tree.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rzJPnfHjKn37",
      "metadata": {
        "id": "rzJPnfHjKn37"
      },
      "outputs": [],
      "source": [
        "# Get a graph with the importance of each feature\n",
        "%matplotlib inline\n",
        "pd.Series(tree.feature_importances_, index = X.columns).plot.barh(figsize=(25, 10));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb5892be",
      "metadata": {
        "id": "bb5892be"
      },
      "source": [
        "## Proceed to classification (processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0BSyE3buIKaX",
      "metadata": {
        "id": "0BSyE3buIKaX"
      },
      "source": [
        "### Dummy classifier\n",
        "* Create a dummy classifier to get the worst cases to compare with\n",
        "* It is expected that the tested classifiers get better results that the dummy one\n",
        "* Use different strategies for the dummy **classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iCJ39xLIINX4",
      "metadata": {
        "id": "iCJ39xLIINX4"
      },
      "outputs": [],
      "source": [
        "for strategy in ['most_frequent', 'stratified', 'prior', 'uniform']:\n",
        "  dummy = DummyClassifier(strategy = strategy, random_state = 0)\n",
        "  # Fit\n",
        "  start = time()\n",
        "  dummy.fit(X_train_balanced, y_train_balanced)\n",
        "  train_time = time() - start\n",
        "  # Compute accuracy and prediction time\n",
        "  start = time()\n",
        "  score = dummy.score(X_test_scaled, y_test)\n",
        "  predict_time = time() - start\n",
        "  # Print results\n",
        "  print(\"{:<15}| score = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(strategy, score, train_time, predict_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ILR7DMvQWLFJ",
      "metadata": {
        "id": "ILR7DMvQWLFJ"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jqZ3wrmBWdlp",
      "metadata": {
        "id": "jqZ3wrmBWdlp"
      },
      "outputs": [],
      "source": [
        "#   ****************Logistic Regression*****************\n",
        "#estimator = LogisticRegression(random_state=0, solver='liblinear', n_jobs=-1)\n",
        "estimator = LogisticRegression(random_state=0, solver='sag', n_jobs=-1)\n",
        "#estimator = LogisticRegression(random_state=0, solver='lbfgs', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "#print(\"Precision score of logistic regression classifier :: \" , metrics.precision_score(y_test, y_pred, average=None, labels=logReg.classes_))\n",
        "#print(\"Recall score of logistic regression classifier :: \" , metrics.recall_score(y_test, y_pred, average=None, labels=logReg.classes_))\n",
        "#print(\"F1 score of logistic regression classifier :: \" , metrics.f1_score(y_test, y_pred, average=None, labels=logReg.classes_))\n",
        "\n",
        "#print(\"ROC curve score of logistic regression classifier :: \" , metrics.roc_score(y_test, y_pred, average=None, labels=logReg.classes_))\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=estimator.classes_)\n",
        "#disp.plot()\n",
        "#plt.title(\"Confusion matrix\")\n",
        "#plt.figure(figsize=(10,10))\n",
        "#plt.show()\n",
        "\n",
        "#%sklearn inline\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test_scaled, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "#fpr, tpr, thresholds = metrics.roc_curve(y_test, y_score)\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "#metrics.RocCurveDisplay.from_predictions(y_test, y_pred, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.show()\n",
        "\n",
        "# Check the section for multiclass\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "# For displaying ROC curve\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_estimator\n",
        "# ROC curve with cross-validation\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test_scaled))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))\n",
        "# Check examples for multiclass\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for logistic regression"
      ],
      "metadata": {
        "id": "z03UeRGVXfvc"
      },
      "id": "z03UeRGVXfvc"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "OUZQtuV3XlTt"
      },
      "id": "OUZQtuV3XlTt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "YdFJbF9Zb2AT",
      "metadata": {
        "id": "YdFJbF9Zb2AT"
      },
      "source": [
        "### Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FV0Il9bnTTAd",
      "metadata": {
        "id": "FV0Il9bnTTAd"
      },
      "outputs": [],
      "source": [
        "#   ****************Multi-layer Perceptron*****************\n",
        "#estimator = MLPClassifier(alpha=1)\n",
        "#estimator = MLPClassifier(alpha=0.0001, solver='adam', verbose=True)\n",
        "#estimator = MLPClassifier(alpha=0.0001, solver='adam', verbose=True, early_stopping=True)\n",
        "estimator = MLPClassifier(alpha=0.001, tol=1e-3, solver='adam', verbose=True, early_stopping=True)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "fig1, ax1 = plt.subplots()\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "fig1.savefig(\"MLP.png\")\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for Multilayer-Perceptron"
      ],
      "metadata": {
        "id": "EVm5JYmtkxEn"
      },
      "id": "EVm5JYmtkxEn"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "myAiApgBk9cd"
      },
      "id": "myAiApgBk9cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "D0OLCkx4cI4S",
      "metadata": {
        "id": "D0OLCkx4cI4S"
      },
      "source": [
        "### Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m20rf12DVmWa",
      "metadata": {
        "id": "m20rf12DVmWa"
      },
      "outputs": [],
      "source": [
        "#   ****************Naive-Bayes*****************\n",
        "estimator = GaussianNB()\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for Naive-Bayes"
      ],
      "metadata": {
        "id": "X7WeoIOqlS2G"
      },
      "id": "X7WeoIOqlS2G"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "rZd897FMlGoW"
      },
      "id": "rZd897FMlGoW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "CmbKfe7j__lO",
      "metadata": {
        "id": "CmbKfe7j__lO"
      },
      "source": [
        "### Gaussian Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1khzyhMAEvH",
      "metadata": {
        "id": "b1khzyhMAEvH"
      },
      "outputs": [],
      "source": [
        "#   ****************Gaussian Process classifier*****************\n",
        "estimator = GaussianProcessClassifier(max_iter_predict=10, random_state=0, n_jobs=-1)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for Gaussian-Process"
      ],
      "metadata": {
        "id": "s8CcaOrelV9x"
      },
      "id": "s8CcaOrelV9x"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "yThY_NUMlHg1"
      },
      "id": "yThY_NUMlHg1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0Wijk73IcLJv",
      "metadata": {
        "id": "0Wijk73IcLJv"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kSh5DD31O-Kv",
      "metadata": {
        "id": "kSh5DD31O-Kv"
      },
      "outputs": [],
      "source": [
        "#   ****************SVM 3th grade polynomial Kernel*****************\n",
        "#estimator = SVC(kernel=\"poly\", verbose=True)\n",
        "estimator = SVC(kernel=\"rbf\", verbose=True)\n",
        "#estimator = SVC(kernel=\"linear\", verbose=True)\n",
        "#estimator = SVC(kernel=\"linear\", gamma=0.1, verbose=True)\n",
        "#estimator = SVC(kernel=\"linear\", gamma=0.001, verbose=True)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for SVM"
      ],
      "metadata": {
        "id": "HhMadcPhlZJu"
      },
      "id": "HhMadcPhlZJu"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "2IbAsqbzlIWw"
      },
      "id": "2IbAsqbzlIWw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qvaHX7IbXYs-",
      "metadata": {
        "id": "qvaHX7IbXYs-"
      },
      "source": [
        "### Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6u_1VUvYXa2Z",
      "metadata": {
        "id": "6u_1VUvYXa2Z"
      },
      "outputs": [],
      "source": [
        "#   ****************Decision Tree*****************\n",
        "#estimator = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "#estimator = DecisionTreeClassifier(random_state=0)\n",
        "estimator = DecisionTreeClassifier(max_depth=20, random_state=0)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FzvufUF_g278",
      "metadata": {
        "id": "FzvufUF_g278"
      },
      "outputs": [],
      "source": [
        "#print(f\"Classes: {estimator.classes_}\")\n",
        "#print(f\"Feature importance: {estimator.feature_importances_}\")\n",
        "#print(f\"Max. features: {estimator.max_features}\")\n",
        "#print(f\"Number of classes: {estimator.n_classes_}\")\n",
        "#print(f\"Number of features: {estimator.n_features_}\")\n",
        "#print(f\"Number of outputs: {estimator.n_outputs_}\")\n",
        "\n",
        "#print(f\"Depth: {estimator.get_depth()}\")\n",
        "#print(f\"Number of leaves: {estimator.get_n_leaves()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee901164",
      "metadata": {
        "id": "ee901164"
      },
      "outputs": [],
      "source": [
        "#tree.plot_tree(decTree)\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for Decision Tree"
      ],
      "metadata": {
        "id": "dqjT6NC8ljyl"
      },
      "id": "dqjT6NC8ljyl"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "SwC05CuGlLYd"
      },
      "id": "SwC05CuGlLYd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "mavCAReZZf22",
      "metadata": {
        "id": "mavCAReZZf22"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rj1sNKXeZi6B",
      "metadata": {
        "id": "Rj1sNKXeZi6B"
      },
      "outputs": [],
      "source": [
        "#   ****************Random Forest*****************\n",
        "#estimator = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1)\n",
        "estimator = RandomForestClassifier(n_estimators=10, max_depth=20, random_state=0, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bMgYY8n0hVYd",
      "metadata": {
        "id": "bMgYY8n0hVYd"
      },
      "outputs": [],
      "source": [
        "#print(f\"Classes: {rf.classes_}\")\n",
        "#print(f\"Feature importance: {rf.feature_importances_}\")\n",
        "#print(f\"Max. features: {rf.max_features}\")\n",
        "#print(f\"Number of classes: {rf.n_classes_}\")\n",
        "#print(f\"Number of features: {rf.n_features_}\")\n",
        "#print(f\"Number of outputs: {rf.n_outputs_}\")\n",
        "\n",
        "#print(f\"Base estimator: {rf.base_estimator_}\")\n",
        "##print(f\"Estimators: {rf.estimators_}\")\n",
        "#for estimator in rf.estimators_:\n",
        "    #print(f\"Estimator: {estimator}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for Random Forest"
      ],
      "metadata": {
        "id": "qY7lms5FlrLd"
      },
      "id": "qY7lms5FlrLd"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "_vzZONZplMrq"
      },
      "id": "_vzZONZplMrq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "99Pd8faZ8lC6",
      "metadata": {
        "id": "99Pd8faZ8lC6"
      },
      "source": [
        "### K Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O7jwNQIE8ow3",
      "metadata": {
        "id": "O7jwNQIE8ow3"
      },
      "outputs": [],
      "source": [
        "#   ****************K Neighbors classifier*****************\n",
        "#estimator = KNeighborsClassifier(n_neighbors = 3, weights = 'distance', n_jobs = 4)\n",
        "estimator = KNeighborsClassifier(n_neighbors = 5, weights = 'distance', n_jobs = -1)\n",
        "\n",
        "# Fit\n",
        "start = time()\n",
        "estimator.fit(X_train_balanced, y_train_balanced)\n",
        "train_time = time() - start\n",
        "\n",
        "# Prediction\n",
        "start = time()\n",
        "y_pred = estimator.predict(X_test_scaled)\n",
        "predict_time = time() - start\n",
        "\n",
        "# Metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Pre-processing\n",
        "y_pred = np.ravel(y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy = {:.4f} | time = {:,.3f}s/{:,.3f}s\".format(accuracy, train_time, predict_time))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=estimator.classes_)\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(cm)\n",
        "\n",
        "#metrics.ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=estimator.classes_, normalize='all', cmap='Greys')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(metrics.classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fig, ax = plt.subplots()\n",
        "metrics.RocCurveDisplay.from_estimator(estimator, X_test_scaled, y_test, alpha=0.8, lw=2, ax=ax)\n",
        "ax.plot([0,1], [0,1], linestyle=\"--\", lw=2, color = \"r\", label = \"Change\", alpha = 0.5)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.show()\n",
        "\n",
        "# Area Under Curve (AUC)\n",
        "\n",
        "#auc = metrics.roc_auc_score(y_test, estimator.decision_function(X_test))\n",
        "# Check this https://scikit-learn.org/stable/modules/model_evaluation.html#roc-auc-binary\n",
        "# where \"estimator.predict_proba(X_test_scaled)[:, 1]\" corresponds to the probability of the class with the \"greater label\", that is why the 1 as the index.\n",
        "y_score = estimator.predict_proba(X_test_scaled)[:, 1]\n",
        "auc = metrics.roc_auc_score(y_test, y_score)\n",
        "print(\"\\nArea Under Curve (AUC) = {:.4f}\".format(auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6e26d91",
      "metadata": {
        "id": "e6e26d91"
      },
      "outputs": [],
      "source": [
        "#print(f\"Classes: {knc.classes_}\")\n",
        "#print(f\"Effective metric: {knc.effective_metric_}\")\n",
        "#print(f\"Effective metric params: {knc.effective_metric_params_}\")\n",
        "#print(f\"N. samples fit: {knc.n_samples_fit_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation for KNN"
      ],
      "metadata": {
        "id": "FzUtnX2nnwA4"
      },
      "id": "FzUtnX2nnwA4"
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=LeaveOneOut(), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "#cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_scores = cross_val_score(estimator, X_train_balanced, y_train_balanced, cv=10, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "cross_validation_time = time() - start\n",
        "print(\"Mean cross-validation scores (Stratified CV) = {:.4f}\".format(np.mean(cross_validation_scores)))\n",
        "print(\"Standard deviation for cross-validation scores (Stratified CV) = {:.4f}\".format(np.std(cross_validation_scores)))\n",
        "print(\"Reported cross-validation time = {:,.3f}s\".format(cross_validation_time))\n",
        "print(\"All cross-validation scores:\\n\", cross_validation_scores)"
      ],
      "metadata": {
        "id": "QjR4YWx7lNmD"
      },
      "id": "QjR4YWx7lNmD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoML with LazyPredict"
      ],
      "metadata": {
        "id": "N87QKhVbUoPg"
      },
      "id": "N87QKhVbUoPg"
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "# Fit\n",
        "start = time()\n",
        "models, predictions = clf.fit(X_train_balanced, X_test_scaled, y_train_balanced, y_test)\n",
        "lazy_classifier_time = time() - start\n",
        "\n",
        "# Print results\n",
        "print(\"time = {:,.3f}s\".format(lazy_classifier_time))"
      ],
      "metadata": {
        "id": "YYTndDIMUtt-"
      },
      "id": "YYTndDIMUtt-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(models)"
      ],
      "metadata": {
        "id": "OqkFBvYvX09M"
      },
      "id": "OqkFBvYvX09M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c791711c",
      "metadata": {
        "id": "c791711c"
      },
      "source": [
        "# AutoML with auto-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4409bbfc",
      "metadata": {
        "id": "4409bbfc"
      },
      "outputs": [],
      "source": [
        "#automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "    #include_estimators=[\"decision_tree\", \"k_nearest_neighbors\", \"random_forest\", ], exclude_estimators=None,\n",
        "    #include_preprocessors=[\"fast_ica\", \"pca\", \"polynomial\", \"no_preprocessing\", \"truncatedSVD\", ], exclude_preprocessors=None,\n",
        "    #n_jobs=4)\n",
        "#automl.fit(X_train, y_train)\n",
        "#y_pred_auto = automl.predict(X_test)\n",
        "#print(\"Accuracy score of AutoML\", metrics.accuracy_score(y_test, y_pred_auto))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6f266e",
      "metadata": {
        "id": "7c6f266e"
      },
      "outputs": [],
      "source": [
        "#automl.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd7f3bb",
      "metadata": {
        "id": "7cd7f3bb"
      },
      "outputs": [],
      "source": [
        "#automl.sprint_statistics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adba58dc",
      "metadata": {
        "id": "adba58dc"
      },
      "outputs": [],
      "source": [
        "#automl.show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e97fb06b",
      "metadata": {
        "id": "e97fb06b"
      },
      "outputs": [],
      "source": [
        "#print(automl.show_models())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "original-diameter",
        "banned-application",
        "6a299ea0",
        "e0d91b4a",
        "a886ccf3",
        "b8a7a938",
        "fdc57427",
        "6391d798",
        "aab82110",
        "e231659f",
        "8cef7799",
        "b1165f40",
        "b5d8e754",
        "7167ee03"
      ],
      "name": "Multifractal based on slide ids.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}